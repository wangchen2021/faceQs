# AI

这类问题多见于中高级前端面试，考察你对 AI 底层技术的理解，以及将 AI 深度融入前端系统的能力。

1. 什么是 RAG？在前端项目中如何应用 RAG？怎么优化它的检索效果？
   
参考回答：RAG 即检索增强生成，核心是通过检索外部知识库的相关信息，辅助大模型生成更精准的回答，避免大模型出现幻觉。前端项目中，我曾在内部文档查询系统中应用 RAG，将项目的接口文档、组件文档存入向量数据库，前端输入查询关键词时，先通过检索接口从向量库中匹配相关文档片段，再将片段与问题一起传给大模型，最终生成精准回答。优化检索效果的方式有三种：一是优化文档分片策略，将长文档按逻辑拆分为短片段，提升匹配精度；二是引入关键词权重机制，对接口名、组件名等核心词汇提高权重；三是添加检索结果过滤，剔除低相关性片段，减少无效信息对大模型的干扰。

2. 什么是 MCP？它和 Function Call 有什么区别？
   
参考回答：MCP 是模型控制协议，主要用于规范大模型与外部系统的交互流程，定义了请求格式、响应规范、错误处理等标准，侧重对交互过程的整体管控。而 Function Call 是大模型的一种能力，允许大模型根据用户需求自动调用预设的函数，比如让模型调用前端的地理位置获取函数，侧重具体功能的触发执行。两者的区别在于，MCP 是交互的 “规则框架”，而 Function Call 是框架内的 “执行手段”。比如在前端天气查询功能中，MCP 规定了模型与天气接口的交互格式，而 Function Call 则是模型触发天气接口调用的具体动作。

3. 如果让你设计一个前端垂直领域的 AI 应用平台（如前端开发助手），你会怎么规划技术方案？
   
参考回答：我会分三层规划方案。一是前端交互层，用 React + TypeScript 开发，设计对话界面、代码编辑器嵌入模块和结果预览区，支持代码高亮、一键复制和实时运行预览；二是中间服务层，用 Node.js 搭建，集成 RAG 和 Function Call 能力，一方面通过向量库存储前端知识库（如 MDN 文档、框架官方教程），另一方面封装代码校验、格式转换等函数供模型调用；三是模型适配层，支持对接 GPT - 4、通义千问等多模型，同时预留本地模型部署接口。此外还会加入 prompt 工程模块，针对前端场景预设模板，比如 “生成 Vue3 组件”“优化 React 性能” 等，提升用户使用效率。上线后还会收集用户反馈，持续优化知识库和模型交互逻辑。

